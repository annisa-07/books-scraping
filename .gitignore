# === Install dependencies (optional di Colab) ===
!pip install requests beautifulsoup4 pandas tqdm

# === Import Library ===
import requests
from bs4 import BeautifulSoup
import pandas as pd
from tqdm import tqdm

# === Fungsi bantu untuk parsing ===

def get_book_info(book_url):
    """Mengambil detail dari setiap buku"""
    base = "https://books.toscrape.com/catalogue/"
    url = book_url if "catalogue" in book_url else base + book_url
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    
    # Ambil informasi umum
    title = soup.find("h1").get_text(strip=True)
    description_tag = soup.select_one("#product_description ~ p")
    description = description_tag.get_text(strip=True) if description_tag else ""
    
    # Informasi tabel
    table = soup.find("table", class_="table table-striped")
    rows = table.find_all("tr")
    data = {row.th.text.strip(): row.td.text.strip() for row in rows}
    
    # Ambil gambar
    image_url = soup.find("img")["src"].replace("../../", "https://books.toscrape.com/")
    
    # Ambil rating
    rating_class = soup.find("p", class_="star-rating")["class"]
    rating = [r for r in rating_class if r != "star-rating"][0]
    
    # Ambil kategori
    category = soup.select("ul.breadcrumb li a")[-1].text.strip()
    
    # Ambil stok
    stock_info = soup.find("p", class_="instock availability").get_text(strip=True)
    import re
    number_stock = re.findall(r"\d+", stock_info)
    number_stock = int(number_stock[0]) if number_stock else 0
    
    # Return data dictionary
    return {
        "code": data.get("UPC"),
        "cover": image_url,
        "title": title,
        "rating": rating,
        "price (excl. tax)": data.get("Price (excl. tax)"),
        "price (incl. tax)": data.get("Price (incl. tax)"),
        "tax": data.get("Tax"),
        "stock status": stock_info,
        "number of stock available": number_stock,
        "description": description,
        "number of reviews": data.get("Number of reviews"),
        "category": category
    }

# === Loop semua halaman ===

base_url = "https://books.toscrape.com/catalogue/page-{}.html"
books_data = []

for page in tqdm(range(1, 51)):  # total ada 50 halaman, masing2 20 buku = 1000 buku
    url = base_url.format(page)
    res = requests.get(url)
    if res.status_code != 200:
        break
    soup = BeautifulSoup(res.text, "html.parser")
    books = soup.select("article.product_pod h3 a")
    
    for b in books:
        book_link = b["href"]
        book_data = get_book_info(book_link)
        books_data.append(book_data)

# === Simpan ke DataFrame ===
df = pd.DataFrame(books_data)
print("Total buku:", len(df))
df.head()

# === Simpan ke file CSV ===
df.to_csv("books_1000.csv", index=False)
print("âœ… Data berhasil disimpan ke 'books_1000.csv'")
